\documentclass[a4paper]{article}
\usepackage[margin=1in]{geometry} % 设置边距，符合Word设定
%\usepackage{ctex}
\usepackage{lipsum}
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{url}
\usepackage{verbatim}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}
\usepackage[section]{placeins}
\usepackage{pdfpages}
\usepackage{indentfirst}

\title{Introduction to AI Coursework}
\author{Runze Yuan 2217498}




\begin{document}

\maketitle

\section{Introduction}

% 说明问题是什么，说明需要哪种算法（回归），说明为什么需要用回归来干这个
\subsection{Question}
% 对于一个发电厂，用它的四个hourly平均环境值来预测其net hourly electrical energy output.

For a Combined Cycle Power Plant, use its hourly average ambient variables to predict the net hourly electrical energy output.

To be specific, the task is to use four input value to predict one output value.

\subsection{Which kind of algorithms to use and why}

Use \textbf{Regression} for the task.

\vspace{5pt}

Reasons:
\begin{itemize}
    \item The aim of regression algorithms is to capture the relationship between inputs and outputs, which is what the task asks for (to predict energy output with four ambient value).
    \item Regression algorithms are capable of predicting future or unseen data.
\end{itemize}

\section{Methods}

\subsection{Algorithms}

In this report I will show results with \textbf{K Neighbors Regressor} and \textbf{Decision Tree Regressor}.

\begin{itemize}
    \item KNR: Find K nearest neighbors in the feature space for the input vector and use the output value of the neighbors to calculate the predicted output.
    \item DTR: DTR builds a decision tree by recursively splitting points into groups based on the result of separation. 
\end{itemize}

\subsection{Metrics}

The Mean Squared Error (MSE), Mean Absolute Error (MAE), and R-squared ($R^2$) are selected as performance metrics for the algorithm. These are common metrics for regression algorithms.

\begin{itemize}
    \item MSE and MAE are metrics that reflects the difference between the predicted result and ground-truth, the lower the better.
    \item $R^2$ reflects the goodness of fitting of the algorithm, and a value close to 1 means a good fit. 
\end{itemize}

\subsection{Baseline}

For the baseline model, use the dummy model in the scikit learn. 

Set all hyperparameters of the dummy to the default value, which means set "parameters" to mean, and both "constants" "quantile" to None.

With these parameters, the dummy model is not an actual regressor and would always output the mean value of the given training output data. 

\subsection{Hyperparameters}


Hyperparameters are parameters that are set prior for models and not changed in the learning process. These parameters control the characteristic of the model and allow adjustments for the user by tuning the hyperparameters.

\begin{itemize}
    \item \textbf{KNR}: In this report I will try to find the optimal \textbf{n\_neighbours}, \textbf{weights}, and \textbf{p}. 
    \begin{itemize}
        \item n\_neighbors: how many nearest neighbors the algorithm use to predict the output value.
        \item weights: changes the weights used in the output generating.
    
        \begin{itemize}
            \item uniform: all nearest neighbors have the same weight.
            \item distance: use distance as weights for the neighbors, distant neighbors have lower weights. 
        \end{itemize}

        \item p: changes the type of distance used in the algorithm
        \begin{itemize}
            \item p=1: apply Manhattan distance for distance calculation.
            \item p=2: apply Euclidean distance for distance calculation. 
        \end{itemize}
        
    \end{itemize}

    \item \textbf{DTR}: In this report I will try to find the optimal \textbf{max\_depth}, \textbf{min\_samples\_leaf}, and \textbf{splitter}
    \begin{itemize}
        \item max\_depth: the maximum depth of the tree.
        \item min\_samples\_leaf: the minimum sample amount for a node to be a leaf node.
        \item splitter: changes the strategy of splitting samples into different groups in nodes.
        \begin{itemize}
            \item best: evaluate all possible splits and apply the best one which have the best performance.
            \item random: apply the best split among a random generated strategy for randomly selected subsets of the features.
        \end{itemize}
        
    \end{itemize}
\end{itemize}

\subsection{}

\section{Result and Analysis}







\end{document}